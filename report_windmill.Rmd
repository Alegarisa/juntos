---
title: "Juntos Project Initial Report"
subtitle: "Educators' Baseline Assessment Cleaning and Recommendations"
author: "Alejandra Garcia Isaza"
date: "March 2021"
output: 
  pagedreport::paged_windmill:
    front_img: "../juntos/front.PNG"
    logo: "../juntos/ceqp_logo.svg"
    img_to_dark: TRUE
    logo_to_white: FALSE
knit: pagedown::chrome_print
main-color: "#65955E"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)

library(rio)
library(here)
library(tidyverse)
library(haven)
library(janitor)
library(knitr)
library(surveytoolbox)
library(sjPlot)
library(kableExtra)
library(psych)

```

# Juntos Project Description {-}

## Study and intervention details {-}

The *Juntos* Project was a three-year study led by the University of Oregon’s Center for Equity Promotion [CEQP.](https://ceqp.uoregon.edu/). The project developed a culturally specific family–school partnership intervention, *Conexiones: Families and Schools United for Equity* (hereafter referred to as *Conexiones*), designed to enhance Latino parents’ and educators’ capacities to effectively support Latino student success.

The *Conexiones* curricula was built on Latino cultural assets, addressed common challenges confronting immigrant students and families in terms of school success, and utilized effective strategies for increasing educators’ awareness of Latino cultures and the barriers that exist for Latino immigrant students and families in schools. It also focused on building effective family-school communication and partnerships with the aim of improving Latino students’ academic success. 

The six participating schools belonged to three different school districts in the state of Oregon and were randomly assigned to either a control group or a intervention group that received the *Conexiones* intervention program. Study participants completed assessments at three different time points (baseline, immediately post-intervention, and 12-month post-intervention). The complete dataset in the project is made of three waves of data with separate assessments for each participant type (parents, students, and educators). 

```{r echo=FALSE, out.width="50%", fig.align="center"}

knitr::include_graphics("../juntos/ceqp_logo.PNG")
```

\pagebreak

## Report details {-}

This report focuses only on the educators' baseline assessment and is intended to describe the data cleaning process with the aim of guiding CEQP's researchers and data analysts in the procedures performed to the dataset. A secondary aim is to help CEQP staff with data management responsibilities to replicate these procedures in subsequent waves of data and future projects. 

The report will also include a brief description of the sociodemographic characteristics of the study participants, the scale creation process, the average scores of participants’ responses in regards to major study constructs, and recommendations for more advanced statistical analyses that link the different types of participants in the study. 

In the appendix section, data analysts interested in using this dataset will find a codebook with all the items, variable names, and response options. 


```{r echo=FALSE, out.width="50%", fig.align="center"}

knitr::include_graphics("../juntos/CEQP_final_panel_3.jpg")
```


```{r echo=FALSE, out.width="50%", fig.align="center"}

knitr::include_graphics("../juntos/CEQP_final_panel_6.jpg")
```

```{r echo=FALSE, out.width="50%", fig.align="center"}

#knitr::include_graphics("../juntos/CEQP_final_panel_7.jpg") # including this image produces a timeout error :/
```


# Data Cleaning procedures {-}

The following section describes the data cleaning procedures I performed in the baseline assessment of the educators' dataset.

I performed data cleaning procedures using the [R](https://www.r-project.org/) and [R Studio](https://rstudio.com/) softwares, but had in mind that end users of the cleaned datasets will likely be SPSS users, thus, I exported the cleaned dataset to a *.sav* file.

## The dataset {-}

```{r include=FALSE}

w1_raw_elt <- read_sav(here("nopublish", "ELT W1 ERC 11.11.2020.sav"))
```

The raw dataset had 43 observations and 202 variables of which 17 were metadata variables created by Qualtrics, the software used to develop the assessment surveys. Of the 43 observations, one case, participant with `id` 153 had incomplete data. I called the raw dataset downloaded directly from Qualtrics as `w1_raw_elt` which stands for wave one of the raw data from the equity leadership team (i.e. elt).

### Initial cleaning

In the following code, I created a new dataframe `elt_w1_clean` where I selected out all but one of the metadata variables, `response_id`. This variable is an unique identifier assigned by Qualtrics that resulted handy in dealing with duplicated ids. 

Other simple data cleaning procedures are noted in the comments marked with a # sign using the [clean_names](https://www.rdocumentation.org/packages/janitor/versions/1.2.0/topics/clean_names), [select](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/select), [rename](https://www.rdocumentation.org/packages/plyr/versions/1.8.6/topics/rename), and [arrange](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/arrange) functions. 

```{r}

elt_w1_clean <- w1_raw_elt %>% 
  clean_names() %>% # function that formats variables' names
  select(-1:-8, -10:-17, -202) %>% # selecting out columns with metadata
  rename(c("id" = "pj")) %>% # renaming id variable.
  arrange(id) # ordering participants ids in descending order
```

### Dealing with duplicated ids

When evaluating if the dataframe had duplicated ids, I found that `id` 257 was duplicated and there was no `id` 254. 

In the table below, I am just showing a few variables and participants from `school` 2. 


```{r echo=FALSE}

d <- elt_w1_clean %>%
  select(1:3, 7:9) %>%
  filter(id > 250 & id < 350)
```

<p>&nbsp;</p>

```{r echo=FALSE}

d %>%
  kbl() %>%
  kable_material(c("striped", "hover", font_size = 7)) %>%
  row_spec(6, color = "black", background = "#F3E35A")
```

After checking with CEQP's research assistant, I corroborated that one of the duplicated cases of `id` 257 in fact was `id` 254. I fixed this mistake with the code below using the `response_id` variable and the  [mutate](https://dplyr.tidyverse.org/reference/mutate.html) and [case_when](https://dplyr.tidyverse.org/reference/case_when.html) functions. 

The combination of these two functions is creating a new variable (that I am naming the same as it was, `id`) to follow the condition that if the variable `response_id` has the "R_6EELe7Uuwi9W7zX" value, the `id` value should be recoded as "254".  

```{r}

elt_w1_clean <- elt_w1_clean %>%
  mutate(id = case_when(response_id == "R_6EELe7Uuwi9W7zX" ~ "254",
                        TRUE ~ as.character(id))) %>%
  arrange(id)
```

### Dealing with survey coding errors

The id protocol followed in CEQP projects is very straightforward. They use three digits for each individual participant id and use the first of these three digits to indicate the school id. In this system, ids in the 100’s would belong to school 1, ids in the 200’s to school 2, and so on.

By visual inspection I dentified that the first digit of the indvidual ids in the `id` variable did not correspond to the ids in the school id variable `school` for schools 3, 4, 5, and 6. In the table below, I selected four variables and only the first row of data of each of the six schools to ilustrate this point. 

```{r echo=FALSE}

d2 <- elt_w1_clean %>%
  select(2, 3, 7:9) %>%
  filter(id == 150 | id == 250 |id == 350 |id == 450 |id == 550 |id == 650)
```

```{r echo=FALSE}

d2 %>%
  kbl() %>%
  kable_material(c("striped", "hover", font_size = 7)) %>%
  row_spec(3:6, color = "black", background = "#F3E35A")
```

As can be seen in the table above, ids in the 300's are coded to belong to `school` 4 and ids in the 400's are coded to belong to `school` 3. I am calling this flip-flopped school ids. Schools 5 and 6 were also flip-flopped. 

At first, I thought that this could be due to an error in the data exporting process and it seemed like an easy enough fix to make. I thought I just needed to recode the names of the levels of the `school` variable. Later I found that this fix did not solve the issue. It took me a couple of months to identify that the error was coded in the Qualtrics survey.

\pagebreak

The images below are screenshots of the same raw data SPSS file downloaded directly from Qualtrics. In figure 1, it can be seen that when the *value labels* button is "on" (i.e. showing value labels and not values), it appears as if there was no flip-flop because the names of the schools coincided with the numbers that were assigned to them. Indeed, school "K" was school 3 and its participants were identified with ids in the 300's and school "A" was school 4 and its participants were identified with ids in the 400's, and so on.

```{r echo=FALSE, out.width="75%", fig.cap="Value labels button on.", fig.align="center"}

knitr::include_graphics("../juntos/val_lab_on.PNG")
```

\pagebreak

This changed when the *value labels* button was "off". In the image below, the flip-flopped school ids is evident again: 

```{r echo=FALSE, out.width="75%", fig.cap="Value labels button off", fig.align="center"}

knitr::include_graphics("../juntos/val_lab_off.PNG")
```

This survey coding error meant that the `school` variable's value labels properly corresponded to the participants' ids, but the variable's values did not. Instead of recoding the values, I decided to create a new variable called `school_id` and delete the flawed original variable `school`. 

In the code below, I created a new dataframe `elt_w1_clean_2` where I used the first digit of the individual participant id variable `id` as the reference for the new `school_id` variable, following CEQP'S id protocol. I also created a new variable called `condition` to indicate which schools were randomly assigned to the control group (coded as 1) or to the intervention group (coded as 2). 

I coded schools identified with a `school_id` odd number (1, 3, and 5) as the control schools and the schools identified with an even number (2, 4, and 6) as the intervention schools, as directed by CEQP's research assistant. Finally, I also created a `wave` variable to indicate the wave of the data. Note that I am creating all of these new variables with the [mutate](https://dplyr.tidyverse.org/reference/mutate.html) function.

\pagebreak

```{r}

elt_w1_clean_2 <- elt_w1_clean %>%
  mutate(school_id = str_sub(id, 1, 1), # new school id variable
         condition = case_when(
           school_id == "1" | school_id == "3" | school_id == "5" ~ "1",
           school_id == "2" | school_id == "4" | school_id == "6" ~ "2")) %>% # new condition variable
  select(school_id, condition, everything()) %>%
  add_column(wave = 1, .before = 9) %>% # new wave variable
  select(- school) # selecting out (i.e. deleting) school variable
```

The `condition` and `school_id` variables I created in the previous code were string variables. In the code below I created a new dataframe `elt_w1_clean_3` where I coerced these variables to be numeric so they can be used in quantitative analyses using the [as.numeric](https://www.rdocumentation.org/packages/h2o/versions/3.32.0.1/topics/as.numeric) function. I also added value labels with the [set_vall](https://nicedoc.io/martinctc/surveytoolbox) function so that SPSS users can use the *value labels* button. 

In the code below I also fixed a response option coding error I identified in the variable `q68`. Throughout most of the survey, response options were coded as "Strongly Disagree" = 1, "Disagree" = 2, "Agree" = 3, "Strongly Agree" = 4, "No response" = 99; however, in variable `q68` the response option "No response" was coded as "5". 

I fixed this using the [ifelse](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/ifelse) function, specifying that if this variable had a response of 5, it should be changed to 99. Finally, I set the variable and value labels with the [set_varl](https://nicedoc.io/martinctc/surveytoolbox) and [set_vall](https://nicedoc.io/martinctc/surveytoolbox) functions, respectively, because sometimes procedures performed with R strips out these labels. 


```{r}

elt_w1_clean_3 <- elt_w1_clean_2 %>%
  mutate(condition = as.numeric(condition),
         condition = set_vall(condition, c("control" = 1, "intervention" = 2)),
         school_id = as.numeric(school_id),
         school_id = set_vall(school_id, c("cascade" = 1, "prairie_mountain" = 2, "kelly" = 3, "ata" = 4, "briggs" = 5, "agnes_stewart" = 6)),
         q68 = ifelse(q68 == 5, 99, q68),
         q68 = set_varl(q68, "When I communicate with Latino families, I keep in mind that many Latino parents may not understand how to navigate the educational system in this
country."),
         q68 = set_vall(q68, c("Strongly Disagree" = 1, "Disagree" = 2, "Agree" = 3, "Strongly Agree" = 4, "No response" = 99)))
```

### Dealing with split out responses from multiple choice, unique answer variables

In this dataset, several multiple choice variables that were originally meant to have a single answer, were spread out as if they allowed to have multiple answers. I believe this was because in the Qualtrics survey development process, the option for *Multiple answer* was selected, instead of *Single answer*. 

```{r echo=FALSE, out.width="75%", fig.cap="Qualtrics survey development", fig.align="center"}

knitr::include_graphics("../juntos/multi_answ.PNG")
```


When this happens, participants could select mutually exclusive options, like this:

```{r echo=FALSE, out.width="50%", fig.cap="Qualtrics survey preview", fig.align="center"}

knitr::include_graphics("../juntos/multi_answ_look.PNG")
```

\pagebreak

When *Multiple answer* is selected, Qualtrics splits these multi-value fields into columns, assigning a value of 1 if a response option is chosen and a value of 0 if a response option is not chosen. In the following code, I collapsed the Spanish variable that was split out so it could be easily used in analyses. To avoid overwhelming the reader, I am omitting the code I used to collapse other language variables. I used the same procedure in all of these variables. 

In the code below, the function [pivot_longer](https://tidyr.tidyverse.org/articles/pivot.html) makes the dataframe "long" as it increases the number of rows and decreases the number of columns. This function gathers variables' names under the new variable `item_2` and gathers the values of these variables under the new variable `spanish_comfort`. Then, I chose only the options that had a value of 1, indicating when a participant chose that response option. 

Finally, I recoded the response options to follow this scheme: "Not at all comfortable" = 1, "Somewhat comfortable" = 2, "Comfortable" = 3, "Very comfortable" = 4, "No response" = 99. 

```{r include=FALSE}
# NOT including this code chunk in report. Just adding it to deal with a pandoc error. 

# collapsing english variables
eng <- elt_w1_clean_3 %>% 
  select(id, starts_with("q132_1")) %>% 
    pivot_longer(
      cols = starts_with("q132_1"),
      names_to = "item_1",
      values_to = "english_comfort",
      values_drop_na = TRUE) %>% 
   filter(english_comfort == 1) %>%
  mutate(english_comfort = case_when(item_1 == "q132_1_1" ~ "1",
                                     item_1 == "q132_1_2" ~ "2",
                                     item_1 == "q132_1_3" ~ "3",
                                     item_1 == "q132_1_4" ~ "4",
                                     item_1 == "q132_1_99" ~ "99",
                        TRUE ~ as.character(english_comfort)))  %>%
  select(-item_1)

# collapsing spanish variables
spa <- elt_w1_clean_3 %>%
  select(id, starts_with("q132_2")) %>% 
    pivot_longer(
      cols = starts_with("q132_2"),
      names_to = "item_2",
      values_to = "spanish_comfort",
      values_drop_na = TRUE) %>% 
   filter(spanish_comfort == 1) %>%
  mutate(spanish_comfort = case_when(item_2 == "q132_2_1" ~ "1",
                                     item_2 == "q132_2_2" ~ "2",
                                     item_2 == "q132_2_3" ~ "3",
                                     item_2 == "q132_2_4" ~ "4",
                                     item_2 == "q132_2_99" ~ "99",
                        TRUE ~ as.character(spanish_comfort))) %>%
  select(-item_2) 

# id 454 is duplicated. In w1_raw it shows that this participant chose options 1 and 2.

# fixing duplicate
spa_2 <- spa %>% 
  distinct(id, .keep_all = TRUE) # Option 1, "not at all comfortable" was chosen because the duplicate was the second option.  

# joining english and spanish variables
langs <- left_join(eng, spa_2) 

# collapsing other language 1 variables
other_1 <- elt_w1_clean_3 %>% 
  select(id, starts_with("q132_3"), -q132_3_text) %>% 
    pivot_longer(
      cols = starts_with("q132_3"),
      names_to = "item_3",
      values_to = "other1_lang_comfort",
      values_drop_na = TRUE) %>% 
   filter(other1_lang_comfort == 1) %>%
  mutate(other1_lang_comfort = case_when(item_3 == "q132_3_1" ~ "1",
                                    item_3 == "q132_3_2" ~ "2",
                                    item_3 == "q132_3_3" ~ "3",
                                    item_3 == "q132_3_4" ~ "4",
                                    item_3 == "q132_3_99" ~ "99",
                        TRUE ~ as.character(other1_lang_comfort)))  %>%
  select(-item_3)

# collapsing other language 2 variables
other_2 <- elt_w1_clean_3 %>% 
  select(id, starts_with("q132_4"), -q132_4_text) %>% 
    pivot_longer(
      cols = starts_with("q132_4"),
      names_to = "item_4",
      values_to = "other2_lang_comfort",
      values_drop_na = TRUE) %>% 
   filter(other2_lang_comfort == 1) %>%
  mutate(other2_lang_comfort = case_when(item_4 == "q132_4_1" ~ "1",
                                    item_4 == "q132_4_2" ~ "2",
                                    item_4 == "q132_4_3" ~ "3",
                                    item_4 == "q132_4_4" ~ "4",
                                    item_4 == "q132_4_99" ~ "99",
                        TRUE ~ as.character(other2_lang_comfort)))  %>%
  select(-item_4)


# joining other 1 and 2 language variables
others <- left_join(other_1, other_2) 


# joining dataframes with all language variables
lang_vars <- left_join(langs, others)


# renaming variables with text input in master dataset (n = 43)
lang_inputs <- elt_w1_clean_3 %>%
  select(id, q132_3_text, q132_4_text) %>%
  rename(c("other1_lang" = "q132_3_text"), c("other2_lang" = "q132_4_text"))

# joining renamed master dataset with all language variables now collapsed to "recover" id 153 data
all_lang_vars <- left_join(lang_inputs, lang_vars)

# recordering all language vars
all_lang_vars <- all_lang_vars %>%
  select(id, english_comfort, spanish_comfort, other1_lang, other1_lang_comfort, other2_lang, everything())

# creating new dataset that joins master dataset with reordered and collapsed lang vars
elt_w1_clean_4 <- left_join(elt_w1_clean_3, all_lang_vars) %>%
  select(-starts_with("q132_")) # deleting all previous language variables that were included in new variables  

# adding value labels on language vars
elt_w1_clean_4 <- elt_w1_clean_4 %>%
  mutate(english_comfort = as.numeric(english_comfort),
         english_comfort = set_vall(english_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)),
         spanish_comfort = as.numeric(spanish_comfort),
         spanish_comfort = set_vall(spanish_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)),
         other1_lang_comfort = as.numeric(other1_lang_comfort),
         other1_lang_comfort = set_vall(other1_lang_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)),
         other2_lang_comfort = as.numeric(other2_lang_comfort),
         other2_lang_comfort = set_vall(other2_lang_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)),
         )
```


```{r eval=FALSE}

# collapsing spanish variables
spa <- elt_w1_clean_3 %>%
  select(id, starts_with("q132_2")) %>% # creating a dataframe with only the id and Spanish variables
    pivot_longer(
      cols = starts_with("q132_2"), 
      names_to = "item_2",
      values_to = "spanish_comfort",
      values_drop_na = TRUE) %>% 
   filter(spanish_comfort == 1) %>%
  mutate(spanish_comfort = case_when(item_2 == "q132_2_1" ~ "1",
                                     item_2 == "q132_2_2" ~ "2",
                                     item_2 == "q132_2_3" ~ "3",
                                     item_2 == "q132_2_4" ~ "4",
                                     item_2 == "q132_2_99" ~ "99",
                        TRUE ~ as.character(spanish_comfort))) %>%
  select(-item_2) # selecting out variable with repetitive information
```

When all the language variables were collapsed I checked if there were duplicated cases and I found that participant identified with `id` 454 chose response option "1" and response option "2". 

```{r echo=FALSE}

d3 <- spa %>%
  filter(id > 450 & id < 550)
```


```{r echo=FALSE}

d3 %>%
  kbl() %>%
  kable_material(c("striped", "hover", font_size = 7)) %>%
  row_spec(4:5, color = "black", background = "#F3E35A")
```

Because I can only assume that this was an entry error given that the choices are, in theory, mutually exclusive: "Not at all comfortable" = 1, vs. "Somewhat comfortable" = 2, I used the [distinct](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/distinct) function to retain only unique values. 

For this case, option 1 = "Not at all comfortable" was retained as the function "assumes" the second option is the duplicative. 

```{r eval=FALSE}

spa_2 <- spa %>% 
  distinct(id, .keep_all = TRUE)
```

```{r echo=FALSE}

spa_2 %>%
  filter(id > 450 & id < 550) %>%
  kbl() %>%
  kable_material(c("striped", "hover", font_size = 7)) %>%
  row_spec(4, color = "black", background = "#F3E35A")
```


The last step in this process was joining the dataframe I created with all the language variables I collapsed (`all_lang_vars`) and the `elt_w1_clean_3` dataframe that had all of the variables. I used the [left_join](https://www.rdocumentation.org/packages/tidytable/versions/0.5.9/topics/left_join.) function to do this. 

In this new dataframe `elt_w1_clean_4` I also coerced the language variables to become numeric so they could be used in quantitative analyses and added the value labels so that SPSS users can use the *value labels* button. I used the code below to do this. 

```{r eval=FALSE, message=FALSE}

elt_w1_clean_4 <- left_join(elt_w1_clean_3, all_lang_vars) %>%
  select(-starts_with("q132_")) # selecting out language variables included now in new language Variables  

elt_w1_clean_4 <- elt_w1_clean_4 %>%
  mutate(english_comfort = as.numeric(english_comfort),
         english_comfort = set_vall(english_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)),
         spanish_comfort = as.numeric(spanish_comfort),
         spanish_comfort = set_vall(spanish_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)),
         other1_lang_comfort = as.numeric(other1_lang_comfort),
         other1_lang_comfort = set_vall(other1_lang_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)),
         other2_lang_comfort = as.numeric(other2_lang_comfort),
         other2_lang_comfort = set_vall(other2_lang_comfort, c("not at all comfortable" = 1, "somewhat comfortable" = 2, "comfortable" = 3, "very comfortable" = 4, "no response" = 99)))
```

As shown, the following variables were the result of the collapsing process described above: `english_comfort`, `spanish_comfort`, `other1_lang_comfort`, and `other2_lang_comfort`. 

### Renaming demographic variables

In the code below, I created a new dataframe `elt_w1_clean_5` where I used the [rename](https://www.rdocumentation.org/packages/reshape/versions/0.8.8/topics/rename) function to rename some of the demographic variables that I used to describe participants's characteristics in the next section of this report. This function uses a "new name" = "old name" pattern. Very straightforward! 

At the end I selected out a few variables that did not have meaningful information. For instance, variable `q127` was a response/no response question that only indicated if participants chose to answer it. The meaningul information was contained in variable `q127_1_text` that was renamed as `age`, which I also coerced to become a numeric variable.  

```{r}

elt_w1_clean_5 <- elt_w1_clean_4 %>%
  rename(c("age" = "q127_1_text"), 
         c("birth_country" = "q128"),
         c("another_birth_country_text" = "q128_2_text"),
         c("age_first_moved_us" = "q129_1_text"),
         c("white" = "q130_1"),
         c("hispanic_latino_spanish" = "q130_2"),
         c("black_african_american" = "q130_3"),
         c("asian" = "q130_4"),
         c("american_indian_alaska_native" = "q130_5"),
         c("indigenous_americas" = "q130_6"),
         c("middle_eastern_north_african" = "q130_7"),
         c("native_hawaiian_pacific_islander" = "q130_8"),
         c("race_ethnicity_other" = "q130_9"),
         c("race_ethnicity_no_response" = "q130_99"),
         c("indigenous_americas_text" = "q130_6_text"),
         c("race_ethnicity_other_text" = "q130_9_text"),
         c("gender_id" = "q131"),
         c("years_in_position" = "q133"),
         c("years_in_school" = "q134"),
         c("equity_leadership" = "q135_1"),
         c("cultural_responsiveness" = "q135_2"),
         c("restorative_practices" = "q135_3"),
         c("diversity" = "q135_4"),
         c("ell" = "q135_5"),
         c("cont_ed_other" = "q135_6"),
         c("cont_ed_na" = "q135_88"),
         c("cont_ed_no_response" = "q135_99"),
         c("cont_ed_other_text" = "q135_6_text")) %>%
  mutate(age = as.numeric(age)) %>% # making variable numeric for QUAN analyses
  select(-q127, -q129, -q131_3_text) # selecting out because they did not have meaningful info
```


# Participant descriptives  {-}

```{r include=FALSE}
# recoding missing values as N/A with function

# vector with missing values in dataset
missing_vals <- c(88, 99, -99)

# function that returns true if values in vector are equal to missing_vals. The function takes a vector x, and specified values of missing data
recode_missing <- function(x, missing_vals = c(88, 99, -99)) {
  test <- x %in% missing_vals
  ifelse(test, NA, x)
}

# function that recodes missing values to NA. The function takes a dataframe with variables with missing data, and specified values of missing data
recode_missing_df <- function(df, missing_vals = c(88, 99, -99)) {
  modify(df, ~recode_missing(.x, missing_vals)) # here uses the function created above
}
```

In the following section, I used descriptive statistics to summarize participants' characteristics. In this analysis, I treated responses such as "99 = not applicable" or "88 = no response" as missing values. Other category of missing values were responses coded by Qualtrics as "-99 = seen but unanswered", when participants were not forced to respond. 

In the code below I created a new dataframe called `elt_w1_clean_6` where I applied a function I created `recode_missing_df` (code of the function not shown) to recode the 88, 99, and -99 values as `NA`, the way R codes missing values. 

The downside of this function is that it strips out the variable and value labels. I dealt with this downside to the best of my coding abilities and I describe what I did later in the report. 

```{r include=FALSE}

elt_w1_clean_6 <- recode_missing_df(elt_w1_clean_5) 
```

## Educator's characteristics {-}

Educators in this first wave of data (*n* = 43) had a mean age of 42.89 years, with an age range between 24 and 62 years of age (see figure 5). The majority of educators were identified as female (74%).  

```{r echo=FALSE, warning=FALSE, fig.height= 4, fig.width=6, fig.cap="Educator's Age by gender", fig.align="center"}

viz_1 <- elt_w1_clean_6 %>%
  filter(response_id != "R_3dFdFPhdRJorWhT") %>%
  mutate(gender_id = as.factor(gender_id),
         gender_id = fct_recode(gender_id,
                           "Male" = "1",
                            "Female" = "2"))
  
ggplot(viz_1, aes(age)) +
  geom_histogram(fill = "#D4AC0D", color = "white", alpha = 0.7, bins = 15) +
  facet_wrap(~ gender_id, nrow = 2) +
  theme_minimal() +
  labs(title = "",
       y = "",
       x = "Age") +
  theme(axis.text = element_text(family = "sans", size = 12),
        axis.title.x = element_text(family = "sans", size = 18, margin = margin(20, 10, 10, 10)),
        strip.text = element_text(family = "sans", size = 15))

```

A little less than half of the educators were teachers (49%), followed by administrators (16%) and other classified staff (16%). The remaining of the sample (19%) was comprised of educational assistants, counselors, and other certified staff. A little more than half of the educators had been in their current career position, regardless of school site, for over 10 years. About 12% of the educators had been in their current career position for less than a year. 

All but four of the educators were born in the United States (U.S.). These four educators traced back their roots to Mexico or El Salvador and report coming for the first time to the U.S. when they were between 11 and 24 years of age. The entirety of the educators in the sample felt either *very comfortable* or *comfortable* speaking in English, but only about 20% felt the same way speaking in Spanish.

```{r echo=FALSE, fig.height= 5, fig.width=7, fig.cap="Educator's Races/Ethnicities and Roles", fig.align="center"}

tidy_d <- elt_w1_clean_6 %>%
  select(4, 5, 136, 139:147, 151, 152, 163, 164) %>%
  gather(race, count, 4:12) %>%
  filter(count == 1)

viz_2 <- tidy_d %>%
  mutate(race = as.factor(race),
         race = fct_recode(race,
                           "White" = "white",
                            "Other race/ethnicity" = "race_ethnicity_other",
                            "Indigenous Latin America" = "indigenous_americas",
                            "Latino" = "hispanic_latino_spanish",
                            "African American" = "black_african_american",
                            "Native American" = "american_indian_alaska_native"),
         years_in_position = as.factor(years_in_position),
         participant_role = as.factor(participant_role),
         participant_role = fct_recode(participant_role,
                           "Administrator" = "1",
                            "Teacher" = "2",
                            "Counselor" = "3",
                            "Educational Assistant" = "4",
                            "Classified staff" = "5",
                            "Certified staff" = "6"))

  
ggplot(viz_2, aes(fct_relevel(race, "White", "Latino"))) +
  geom_bar(aes(fill = participant_role), position = position_dodge2(preserve = "single")) +
  scale_y_continuous() +
  scale_fill_viridis_d("Educator's roles", option = "plasma") +
  theme_minimal() +
  labs(title = "",
       y = "",
       x = "") +
  theme(axis.text.x = element_text(family = "sans", size = 12, angle = 45, hjust = 1),
        legend.text = element_text(family = "sans", size = 10)) 
```

As can be seen in figure 6, educators in this sample were overwhelmingly White (81%). Other educators identified as Latino (12%), Native American (7%), Indigenous from Latin America (2%), and African American (2%). Roughly 5% identified as other race/ethnicity ^[In this study, participants were allowed to select as many races or ethnicities they felt identified with, thus, percent of total adds up to more than 100%].


# Study constructs' scales {-}

In this section, I describe the scale creation process of some of the study constructs the intervention was designed to influence. The steps involved in this process were: reverse coding of items, scale reliability check, and scale creation.

## Reverse coding of items {-}

The first step in the scale creation process was to identify which items needed to be reverse coded. Unfortunately, there was no indication in the original survey of which items needed to be reverse coded, so I had to use my subjective judgement to identify them. 

This was a time consuming step because it entailed an item by item and then a scale by scale review. Luckily, once the items were identified, the reverse coding process was really fast because the [likert_reverse](https://rdrr.io/github/martinctc/surveytoolbox/man/likert_reverse.html) function did the "heavy lifting"! Note that I use this function within a mutate function call.

In the code below I created a new dataframe called `elt_w1_clean_6_rev_code` where I included the new reverse coded variables. 

```{r}

elt_w1_clean_6_rev_code <- elt_w1_clean_6 %>%
  mutate(q25 = likert_reverse(q25, top = 4, bottom = 1),
         q73 = likert_reverse(q73, top = 4, bottom = 1),
         q110 = likert_reverse(q110, top = 6, bottom = 1),
         q113 = likert_reverse(q113, top = 6, bottom = 1),
         q114 = likert_reverse(q114, top = 6, bottom = 1),
         q115 = likert_reverse(q115, top = 6, bottom = 1),
         q116 = likert_reverse(q116, top = 6, bottom = 1),
         q123 = likert_reverse(q123, top = 4, bottom = 1),
         q124 = likert_reverse(q124, top = 4, bottom = 1))
```

Here I reverse coded all of the items in the survey that needed to be reverse coded, however, I did not use the first and last two variables, `q25`, `q123`, and `q124` in the scale creation process because they belong to scale constructs other than school climate, family-school relationships, and efficacy. The following are the items I reverse coded and used in the scale creation process described below: 

> 
Item q73: *Regardless of Latino students’ abilities, it seems most Latino students are bound for a vocational career rather than for community college or university studies.*  
Item q110: *When I really try, I can get through to most difficult students.*
Item q113: *If a student did not remember information I gave in a previous lesson, I would know how to increase his/her retention in the next lesson.*  
Item 114: *If a student in my class becomes disruptive and noisy, I feel assured that I know some techniques to redirect him/her quickly.*  
Item q115: *If one of my students couldn't do a class assignment, I would be able to accurately assess whether the assignment was at the appropriate level of difficulty.*
Item q116: *I can get through to even the most difficult or unmotivated students.*  


## Reliability check {-}

Once I completed the reverse coding step, I checked the reliability of the scales of the study constructs mentioned before. I used Chronbach's alpha as a measure of the internal consistency of the scale and I followed these guidelines to indicate the level of the scale's reliability:

> 
.00 to .69 = Poor reliability  
.70 to .79 = Fair reliability  
.80 to .89 = Good reliability  
.90 to .99 = Excellent/Strong reliability  

In the code below, first, I created a dataframe only with the specific items of interest, selecting them by their variable name in the dataset. Then, I checked the internal consistency of this dataframe or scale using the [alpha](https://www.rdocumentation.org/packages/psych/versions/2.0.12/topics/alpha) function. I followed this same procedure for all of the scales. 

The first scale I checked was school climate. In the original survey that educators completed, the prompt indicated that these items referred to general school climate. Despite my efforts to find the original measure that was used as a reference to create these items, I was not succesful in finding it. 

For what I gathered of the survey development process, different items from different measures were used, however, the survey developer(s) did not leave a precise record of what items belonged to what measure.

It is likely that several items from this scale were adapted from items in Part A: *General Climate Factors* of the public domain Charles F. Kettering Instrument (Fox et al., 1973) and *the Omnibus T-Scale* (Hoy & Tschannen-Moran, 2007). It is important to note that these two measures had a number of subscales within them, thus, it is possible that the scale named here as *general school climate* also has subscales. This scale is a good candidate for further Exploratory and Confirmatory Factor Analyses (EFA and CFA).

Following the guidelines stated above, the general school climate scale has an excellent internal consistency or reliability. It is important to say, however, that because Cronbach’s alpha increases as the number of item increases, this high score may be due to the high number of items included in the scale (24 items). 

For this scale, higher scores indicate better school climate. 


```{r eval=FALSE}

climate_gen <- elt_w1_clean_6_rev_code %>%
  select(q1:q24) %>% 
  data.frame() 

alpha(climate_gen) # alpha = .92 -->  excellent consistency
```

For the diversity engagement, the equity self-efficacy, the school-family relationship, and the teacher-family relationship scales I was not able to locate any measures of reference. These were probably created by the survey developer(s). 

The diversity engagement scale has 14 items and it has an excellent internal consistency or reliability, however, by reading the items it could be seen that several topics are alluded to, from professional development to coonecting student with resources. This scale is also a good candidate for EFA and CFA. 

For this scale, higher scores indicate more engagement of diversity. 
# (check this tomorrw)

```{r eval=FALSE}

diver_engage <- elt_w1_clean_6_rev_code %>%
  select(q36:q49) %>% 
  data.frame()

alpha(diver_engage) # alpha = .92 -->  excellent consistency
```


The equity self-efficacy scale... 

```{r eval=FALSE}

equity_self_eff <- elt_w1_clean_6_rev_code %>%
  select(q50:q55) %>% 
  data.frame()

alpha(equity_self_eff) # alpha = .89 -->  good consistency
```

The school-Latino families relationship scale...

```{r eval=FALSE}

scho_lat_fam_rel <- elt_w1_clean_6_rev_code %>%
  select(q56:q64) %>% 
  data.frame() # alpha = --> .84 good consistency

alpha(scho_lat_fam_rel)

scho_lat_fam_rel_2 <- elt_w1_clean_6_rev_code %>%
  select(q56:q64, q70:q72) %>% 
  data.frame() 

alpha(scho_lat_fam_rel_2) # alpha = .88 --> good consistency
```

The teacher-Latino families relationship scale...

in the `teach_lat_fam_rel` scale, .69poor consistency, message suggests reverse coding items q73 and q75. 


in the `teach_lat_fam_rel_2` scale, .75 fair consistency, message suggests reverse coding item q75. 
```{r eval=FALSE}

teach_lat_fam_rel <- elt_w1_clean_6_rev_code %>%
  select(q65:q76) %>%
  data.frame() # (q73 was reverse coded)

alpha(teach_lat_fam_rel) # alpha = .69 --> poor consistency, better if dropping q73 and q75

teach_lat_fam_rel_2 <- elt_w1_clean_6_rev_code %>%
  select(q65:q69, q74:q76) %>% # leaving out q70:q73
  data.frame()

alpha(teach_lat_fam_rel_2) # alpha = .75 --> fair consistency
```

The teacheer self efficacy was adapted from... Hoy & Woolfolk (1993)

the response options changed competely from previous items (1-6) strongly agree to strongly disagree. 

talk about the way I reverse coded items and the 2 subscales. 
`teach_self_eff_all` message suggests reverse: q112

`teach_eff_gen` no message

`teach_eff_per` no message

```{r eval=FALSE}
teach_self_eff_all <- elt_w1_clean_6_rev_code %>% 
  select(q108:q117) %>% 
  data.frame() # q110, q113, q114, q115, q116 were reverse coded)

alpha(teach_self_eff_all) # alpha = .74 --> fair consistency

teach_eff_gen <- elt_w1_clean_6_rev_code %>% # general teaching efficacy dimension in original measure
  select(q108, q109, q111, q112, q117) %>% 
  data.frame()

alpha(teach_eff_gen) # alpha = .73 --> fair consistency

teach_eff_per <- elt_w1_clean_6_rev_code %>% # personal teaching efficacy dimension in original measure
  select(q110, q113, q114, q115, q116) %>% 
  data.frame() # all items were reverse coded)

alpha(teach_eff_per) # alpha = .88 --> good consistency
```


References 

Fox, R. S., Boles, H. E., Brainard, E., Fletcher, E., Huge, J. S., Martin, C. L., Maynard, W., Monasmith, J., Olivero, J., Schmuck, R., Shaheen, T. A., Stegeman, W. H. (1973) School climate improvement: a challenge to the school administrator. Bloomington, IN: Phi Delta Kappa Educational Foundation.

Hoy, W. K., & Tschannen-Moran, M. (2007). The conceptualization and measurement of faculty trust in schools: The Omnibus T-Scale. In Hoy, W. K., & DiPaola, M. (Eds.). Essential ideas for the reform of American schools (pp. 87-114). Charlotte, NC: IAP.

Hoy, W. K., & Woolfolk, A. E. (1993). Teachers' sense of efficacy and the organizational health of schools. The elementary school journal, 93(4), 355-372.


## Scale creation {-}


```{r}
elt_w1_scales <- elt_w1_clean_6_rev_code %>%
  rowwise() %>% 
  mutate(climate_general = mean(c(q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, q11,  q12, q13, q14, q15, q16, q17, q18, q19, q20, q21, q22, q23, q24), na.rm = TRUE),
         school_engage_diversity = mean(c(q36, q37, q38, q39, q40, q41, q42, q43, q44, q45, q46, q47, q48, q49), na.rm = TRUE),
         equity_self_efficacy = mean(c(q50, q51, q52, q53, q54, q55), na.rm = TRUE),
         school_lat_fam_rel = mean(c(q56, q57, q58, q59, q60, q61, q62, q63, q64, q70, q71, q72), na.rm = TRUE),
         teacher_lat_fam_rel = mean(c(q65, q66, q67, q68, q69, q74, q75, q76), na.rm = TRUE),
         gen_teaching_efficacy = mean(c(q108, q109, q111, q112, q117), na.rm = TRUE),
         per_teaching_efficacy = mean(c(q110, q113, q114, q115, q116), na.rm = TRUE)) %>%
  select(1:7, 169:175)
```


# Average Scores of Major Study Constructs  {-}




```{r include=FALSE}

# descriptive stats function

# function that takes a df and returns a df with only the numeric columns
only_numeric <- function(df) {
  select_numeric <- dplyr::select_if(df, is.numeric)
  return(select_numeric)
}

# a list with the functions we want
smry <- list(mean = function(x) round(mean(x, na.rm = TRUE), 2), 
             sd = function(x) round(sd(x, na.rm = TRUE), 2),
             min = function(x) min(x, na.rm = TRUE),
             max = function(x) max(x, na.rm = TRUE))

# wrapping solution in a function
descriptives <- function(df) {
  select_numeric <- only_numeric(df)
  mean_sd <- map_df(select_numeric, function(col) map_df(smry, ~.x(col)),
       .id = "column")
  return(mean_sd)
}

```

```{r}
# using the function descriptives I created above
#descrip_table <- descriptives(elt_w1_clean_6) # use df that has scales, not elt_w1_clean_6
```


## Educator's average scores {-}

...


note: include plots with average scores

# Recommendations  {-}

I recommend...

* id protocol
  + When developing the id protocol for schools, make sure that both values and values labels coincide. 
  + Assign an unique identifier for each participant and an unique identifier per family. 

* Survey developmnet
  + When creating items for a survey, indicate which items need to be reverse coded. 

# Appendix  {-}

```{r echo=FALSE}
view_df(elt_w1_clean_5) # change for final_elt_w1 when done.
```

