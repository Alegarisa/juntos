---
title: "Juntos Project Initial Report"
subtitle: "Baseline Assessment Cleaning and Recommendations"
author: "Alejandra Garcia Isaza"
date: "March 2021"
output: 
  pagedreport::paged_windmill:
    front_img: "../juntos/front.PNG"
    logo: "../juntos/ceqp_logo.svg"
    img_to_dark: TRUE
    logo_to_white: FALSE
knit: pagedown::chrome_print
main-color: "#65955E"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(here)
library(tidyverse)
library(haven)
library(knitr)
library(surveytoolbox)
library(sjPlot)
library(kableExtra)

```

# Juntos Project Description {-}

## Study and intervention details {-}

The *Juntos* Project was a three-year study led by the University of Oregon’s Center for Equity Promotion [CEQP.](https://ceqp.uoregon.edu/). The project developed a culturally specific family–school partnership intervention, *Conexiones: Families and Schools United for Equity* (hereafter referred to as *Conexiones*), designed to enhance Latino parents’ and educators’ capacities to effectively support Latino student success.

The *Conexiones* curricula was built on Latino cultural assets, addressed common challenges confronting immigrant students and families in terms of school success, and utilized effective strategies for increasing educators’ awareness of Latino cultures and the barriers that exist for Latino immigrant students and families in schools. It also focused on building effective family-school communication and partnerships with the aim of improving Latino students’ academic success. 

The six participating schools belonged to three different school districts in the state of Oregon and were randomly assigned to either a control group or a intervention group that received the *Conexiones* intervention program. Study participants completed assessments at three different time points (baseline, immediately post-intervention, and 12-month post-intervention). The complete dataset in the project is made of three waves of data with separate assessments for each participant type (parents, students, and educators). 

\pagebreak

## Report details {-}

This report will be focusing only on the baseline assessment and is intended to describe the data cleaning process with the aim of helping CEQP staff replicate these procedures in subsequent waves of data and future projects. The report will also include a brief description of the sociodemographic characteristics of the study participants, the scale creation process, the average scores of participants’ responses in regards to major study constructs, and recommendations for more advanced statistical analyses that link the different types of participants in the study.

```{r, echo=FALSE, out.width="50%", fig.align="center"}

knitr::include_graphics("../juntos/ceqp_logo.PNG")
```

# Data Cleaning procedures {-}

The following section describes the data cleaning procedures performed in each of the participant's type datasets.

## Educator's dataset {-}

```{r, include=FALSE}

w1_raw_elt <- haven::read_sav(here("nopublish", "ELT W1 ERC 11.11.2020.sav"))
```

The raw dataset had 43 observations and 202 variables of which 17 were metadata variables created by Qualtrics, the software used to create the assessment surveys. In the following code, I removed all but one of the metadata variables, `response_id`, that is an unique identifier assigned by Qualtrics that resulted handy in dealing with duplicated ids. Other data cleaning procedures are described in the comments marked with a # sign. 

```{r}

elt_w1_clean <- w1_raw_elt %>% 
  janitor::clean_names() %>% # function that formats variables names
  select(-1:-8, -10:-17, -202) %>% # selecting out columns with metadata
  rename(c("id" = "pj")) %>% # renaming id variable
  arrange(id) # ordering participants ids in descending order
```

When evaluating if the dataset had duplicated ids, I found that `id` 257 was duplicated and there was no `id` 254. 

```{r, echo=FALSE}

d <- elt_w1_clean %>%
  select(1:3, 7:9) %>%
  filter(id > 250 & id < 350)
```


```{r, echo=FALSE}

d %>%
  kbl() %>%
  kable_material(c("striped", "hover", font_size = 7)) %>%
  row_spec(6, color = "black", background = "#F3E35A")
```

After checking with the CEQP data manager, I corroborated that one of the duplicated cases of `id` 257 in fact was `id` 254. I fixed this mistake with the code below using the `response_id` variable and the [mutate](https://dplyr.tidyverse.org/reference/mutate.html) and [case_when](https://dplyr.tidyverse.org/reference/case_when.html) functions. 

```{r}

elt_w1_clean <- elt_w1_clean %>%
  mutate(id = case_when(response_id == "R_6EELe7Uuwi9W7zX" ~ "254",
                        TRUE ~ as.character(id))) %>%
  arrange(id)
```

The id protocol followed in CEQP projects is very simple. They usually use three digits for each individual participant id and use the first of these three digits to indicate the school. In this system, ids in the 100’s would belong to school 1, ids in the 200’s to school 2, and so on.

By visual inspection I dentified that the first digit of the indvidual ids in the `id` variable did not correspond to the ids in the school id variable `school` for schools 3, 4, 5, and 6. In the table below, I selected four variables and only the first row of data of each of the six schools to ilustrate this point. 

As can be seen in the `school` variable, ids in the 300's are coded to belong to school 4 and ids in the 400's are coded to belong to school 3. I am calling this flip-flopped school ids. Schools 5 and 6 are also flip-flopped. This seemed an easy enough fix to make, but later I found an additional error that was coded in the Qualtrics survey that made it challenging to understand what was happening.

```{r, echo=FALSE}

d2 <- elt_w1_clean %>%
  select(2, 3, 7:9) %>%
  filter(id == 150 | id == 250 |id == 350 |id == 450 |id == 550 |id == 650)

```

```{r, echo=FALSE}

d2 %>%
  kbl() %>%
  kable_material(c("striped", "hover", font_size = 7)) %>%
  row_spec(3:6, color = "black", background = "#F3E35A")
```

In the images below from the raw data SPSS file it can be seen that when value labels are "on", that is, instead of showing the values it shows the labels of the values, it appears as if there was no flip-flop because the names of the schools coincided with the numbers that were assigned to them. Indeed, "Kelly" was school 3 and its participants were identified with ids in the 300's and "ATA" was school 4 and its participants were identified with ids in the 400's. 


```{r, echo=FALSE, out.width="75%", fig.cap="A nice image.", fig.align="center"}

knitr::include_graphics("../juntos/val_lab_on.PNG")
```
\pagebreak

This changed when value labels were "off". In the image below, the flip-flop is evident again: 

```{r, echo=FALSE, out.width="75%", fig.cap="Another nice image.", fig.align="center"}

knitr::include_graphics("../juntos/val_lab_off.PNG")
```

This survey coding error meant that both values and values labels needed to be changed. I decided instead to create a new variable called `school_id` and delete the flawed original variable `school`. In the code below, the individual participant id variable `id` was used as the reference for the new `school_id` variable. 

I also created a new variable called `condition` to indicate which schools were randomly assigned to the control group (coded as 1) or to the intervention group (coded as 2). Finally, I also created a `wave` variable to indicate the wave of the data. 

```{r}

elt_w1_clean_2 <- elt_w1_clean %>%
  mutate(school_id = str_sub(id, 1, 1), # new school id variable
         condition = case_when(
           school_id == "1" | school_id == "3" | school_id == "5" ~ "1",
           school_id == "2" | school_id == "4" | school_id == "6" ~ "2")) %>% # new condition variable
  select(school_id, condition, everything()) %>%
  add_column(wave = 1, .before = 10) %>% # new wave variable
  select(- school) # deleting school variable
```




## Parent dataset {-}

...

## Youth dataset {-}

...

```{r}

```


# Participant descriptives  {-}

Say something about participant characteristics

## Educator's characteristics {-}

...

## Parent characteristics {-}

...

## Youth characteristics {-}

...


# Scale creation and Testing {-}

Say something about scales

## Educator's scales {-}

...

## Parent scales {-}

...

## Youth scales {-}

...

# Average Scores of Major Study Constructs  {-}

Say something about the average scores...

## Educator's average scores {-}

...

## Parent average scores {-}

...

## Youth average scores {-}

...


note: include plots with average scores

# Recommendations  {-}

I recommend...

* id protocol
  + ...