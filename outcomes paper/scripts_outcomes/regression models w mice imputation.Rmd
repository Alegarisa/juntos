---
title: "regression models w mice imputation"
output: html_document
date: "2025-01-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(here)
library(tidyverse)
library(haven)
library(janitor)
library(knitr)
library(surveytoolbox)
library(sjPlot)
library(kableExtra)
library(psych)
library(sjmisc)
library(MVN)
library(stats)
library(AICcmodavg)

library(mice)
library(VIM)
library(MissMech)
# library(miceadds)

theme_set(theme_minimal())
```

### The dataset ###

Note: on may 5, 2025: I made a few changes on some scales, based on more painstakingly reviewing model assumptions for EFA. These changes are reflected in paper I worked with Seth. 

```{r}
d <- read_sav(here("outcomes paper/data_outcomes", "p_y_w1_for_analysesjan25_2.sav")) # 94 rows

view_df(d)
```


```{r}
d1 <- d %>%
  select(school_id, family_id, participant_id, parent_eng_comf, youth_age, youth_gender, acadhwi_1, checkhwi_1, checkhwi_1, struct_1, convfut_1, knowschool_1, selfeffic_1, stratsbi_1, welcome_1, endorse_1, supported_1, ptrel_1, y_sch_eng, y_parsupp, y_parinv, y_hw, gen_grades, grades)

view_df(d1)
```

```{r}
d2 <- d1 %>%
  mutate(parent_eng_comf = as.numeric(parent_eng_comf),
         youth_gender = factor(youth_gender),
         youth_age = as.numeric(youth_age))
# View(d2)
# view_df(d2)
```

# descriptive stats function
```{r include=FALSE}

# function that takes a df and returns a df with only the numeric columns
only_numeric <- function(df) {
  select_numeric <- dplyr::select_if(df, is.numeric)
  return(select_numeric)
}

# a list with the functions we want
smry <- list(n = function(x) length(x),
             n_valid = function(x) sum(!is.na(x)),
             na = function(x) sum(is.na(x)),
             M = function(x) round(mean(x, na.rm = TRUE), 2), 
             SD = function(x) round(sd(x, na.rm = TRUE), 2),
             Min = function(x) round(min(x, na.rm = TRUE), 2),
             Max = function(x) round(max(x, na.rm = TRUE), 2))

# wrapping solution in a function
descriptives <- function(df) {
  select_numeric <- only_numeric(df)
  mean_sd <- map_df(select_numeric, function(col) map_df(smry, ~.x(col)),
       .id = "column")
  return(mean_sd)
}
```


```{r}
descrip_table <- descriptives(d2) %>%
  rename(c("Scale" = "column"))

descrip_table
```


# Inspect missingness patterns

outcomes with no NA:
y_sch_eng       
y_parsupp
y_parinv          
y_hw 
selfeffic_1 

predictors with no NA:
youth_gender
struct_1
convfut_1
knowschool_1
stratsbi_1
welcome_1
endorse_1      
supported_1      
ptrel_1

This figure shows:
80 rows have no missing values
5 rows are missing parent_eng_comf 
1 row is missing grades
3 rows are missing grades and parent_eng_comf
3 rows are missing gen_grades
1 row is missing acadhwi_1 and checkhwi_1
1 row is missing youth_age

```{r}
md.pattern(d2)
```

# Inspect missingness proportions

This plot shows proportion of missingness: 85% is not missing 
```{r}
nice_plot <- aggr(d2, col = c ('cornflowerblue', 'yellow'),
                  numbers = TRUE, sortVars = TRUE,
                  labels = names (d2), cex.axis = .7,
                  gap = 4, ylab = c ("Missing data", "Pattern"))
```
# Create a missingness or margin plot to further inspect missingness
```{r}
marginplot(d2[, c("acadhwi_1", "checkhwi_1")], col = mdc(1:2), cex = 1.2, cex.lab = 1.2, cex.numbers = 1.3, pch = 19) # only 2 variables at a time
```

# Perform Littleâ€™s MCAR test
Get this error message: Error in TestMCARNormality(d2) :More than one missing data pattern should be present.
```{r}
library(RNOmni)  # Alternative package since BaylorEdPsych is unavailable
# TestMCARNormality(d2)
```

```{r}
library(naniar)

gg_miss_upset(d2)
```


### Imputation preprocessing

Following this instructions: https://library.virginia.edu/data/articles/getting-started-with-multiple-imputation-in-r

This person suggest to remove variables that have more than 25% misingness, character variables, and to remove variables that are highly correlated with others as that might mess up the imputations. Also they suggest not make any transformations at this point. 

# Specify a separate imputation model for variables of interest is they are not numerical (code from link above)

# Ordered categorical variables 
poly <- c("patriot_amident", "pid_x")

# Dichotomous variable
log <- c("manuf")

# Unordered categorical variable 
poly2 <- c("china_econ")

meth[poly] <- "polr"
meth[log] <- "logreg"
meth[poly2] <- "polyreg"

```{r}
d3 <- d2 %>%
  select(-school_id, -family_id, -participant_id)

# view_df(d3)

#str(d3) # all except gender (factor) are numerical variables. 
```

### Imputation
```{r}
# We run the mice code with 0 iterations 
imp <- mice(d3, maxit=0)

# Extract predictorMatrix and methods of imputation 
predM <- imp$predictorMatrix
meth <- imp$method # Empty cells in the method matrix mean those variables will not be imputed

head(predM)
```
# Basic imputation using predictive mean matching (PMM), changing default number of imputed data sets from 5 to 50.
```{r}
imputed_data <- mice(d3, 
                     m = 20,
                     method = 'pmm',
                     print =  FALSE)

summary(imputed_data)

imputed_data$data$parent_eng_comf # this is still showing missing data
```

# Check out one of the complete data sets (the second of 20, in this case)
```{r}
imputed_data_set2 <- complete(imputed_data, action = 2)
# View(imputed_data_set2) # if we were doing single imputation, we'd stop here, but we are not.

nice_plot <- aggr(imputed_data_set2, col = c ('cornflowerblue', 'yellow'),
                  numbers = TRUE, sortVars = TRUE,
                  labels = names (d1), cex.axis = .7,
                  gap = 4, ylab = c ("Missing data", "Pattern")) # This plot show that there is no missing values now. 

imputed_data_set2$parent_eng_comf # checking completeness
```
## Now going back to the imputed_data

# Examine strip plot 
```{r}
stripplot(imputed_data, pch = 20, cex = 1.2) # Red dots are imputed values, blue are observed values
```

# Examine kernel density plot
```{r}
densityplot(imputed_data, scales = list(x = list(relation = "free")), layout = c(3, 1)) # Red lines are imputed value distributions, blue are observed value distributions
```

############################################################ standarizing variables - start ##################################################################

# Step 1: Convert to long format for processing
```{r}
imputed_long <- complete(imputed_data, action = "long", include = TRUE)

imputed_long <- imputed_long %>%
  mutate(youth_gender = as.numeric(youth_gender))

colnames(imputed_long)
```

# Step 2: Function to standardize within each imputed dataset
```{r}
standardize <- function(df) {
  df <- df %>%
    mutate(across(c(selfeffic_1, y_sch_eng, y_parsupp, y_parinv, y_hw, gen_grades, grades, parent_eng_comf, youth_age, acadhwi_1, checkhwi_1, struct_1, convfut_1, knowschool_1, stratsbi_1, welcome_1, endorse_1, supported_1, ptrel_1), ~ scale(.)[,1]))  # Standardizing variables
  return(df)
} # STANDARDIZING ALL EXCEPT GENDER THAT IS A FACTOR
```

# Step 3: Apply standardization within each imputed dataset
```{r}
imputed_long <- imputed_long %>%
  group_by(.imp) %>%
  group_modify(~ standardize(.x))

imputed_long <- imputed_long %>%
  mutate(youth_gender = factor(youth_gender),
         youth_gender = relevel(youth_gender, ref = "1")) # male
```

# Step 4: Convert back to `mids` object
```{r}
imputed_data_std <- as.mids(as.data.frame(imputed_long))
```


############################################################# standarizing variables  - end ###############################################################


These models responded the changes I made on the PTIQ endorse (called here endorse2) and p-t relationship scales and the school involvement scale knowschool_1, stratsbi_1). 

knowschool is school familiarity in paper
stratsbi is strategic school inv
welcome is belonging

### Analytic model fitting ###

# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas

# Multiple regression, outcome: y_sch_eng (standardized)
```{r}
# without support
fit1_st <- with(imputed_data_std, lm(y_sch_eng ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + knowschool_1 + stratsbi_1 + welcome_1 + endorse_1 + ptrel_1))

est1_st <- pool(fit1_st)
summary(est1_st) 

pool.r.squared(fit1_st) # 0.22
```


# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: grades (youth report) (standardized)
```{r}
# without support
fit2_st <- with(imputed_data_std, lm(grades ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + knowschool_1 + stratsbi_1 + welcome_1 + endorse_1 +  ptrel_1))

est2_st <- pool(fit2_st)
summary(est2_st)

pool.r.squared(fit2_st) # 0.11
```


# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: hw best practices (standardized)
```{r}
# without support
fit3_st <- with(imputed_data_std, lm(y_hw ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + knowschool_1 + stratsbi_1 + welcome_1 + endorse_1 +  ptrel_1))

est3_st <- pool(fit3_st)
summary(est3_st) # no predictors were significantly related with the outcome

pool.r.squared(fit3_st) # 0.13
```

# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: self efficacy (parent report) (standardized)
```{r}
# without support
fit6_st <- with(imputed_data_std, lm(selfeffic_1 ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + knowschool_1 + stratsbi_1 + welcome_1 + endorse_1 + ptrel_1))

est6_st <- pool(fit6_st)
summary(est6_st)

pool.r.squared(fit6_st) # 0.68
```


# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: gen grades (parent report) (standardized)
```{r}
# without support
fit7_st <- with(imputed_data_std, lm(gen_grades ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + knowschool_1 + stratsbi_1 + welcome_1 + endorse_1 + ptrel_1))

est7_st <- pool(fit7_st)
summary(est7_st)

pool.r.squared(fit7_st) # 0.22
```



because we don't have an objective report of grades, we don't know who was more accurate. Parents sense their kids is in a way affected by their ties to the school. if parents know a lot of school, she is doing well, when in reality is not true. Kids may have info that parents don't have. students are more used to he grading system, more than immigrant parents. limitations - the scale is not great, imo, very highly used.


