---
title: "handling missing values"
output: html_document
date: "2025-01-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(here)
library(tidyverse)
library(haven)
library(janitor)
library(knitr)
library(surveytoolbox)
library(sjPlot)
library(kableExtra)
library(psych)
library(sjmisc)
library(MVN)
library(stats)
library(AICcmodavg)

library(mice)
library(VIM)
# library(miceadds)

theme_set(theme_minimal())
```

Trying to handle trhe missing data 

### The dataset ###

```{r}
d <- read_sav(here("outcomes paper/data_outcomes", "p_y_w1_for_analysesjan25.sav")) # 94 rows

# view_df(d)
```


```{r}
d1 <- d %>%
  select(school_id, family_id, participant_id, parent_eng_comf, youth_age, youth_gender, acadhwi_1, checkhwi_1, checkhwi_1, struct_1, convfut_1, knowschool_1, selfeffic_1, parnets_1, welcome_1, endorse_1, supported_1, ptrel_1, y_sch_eng, y_parsupp, y_parinv, y_hw, gen_grades, grades)

# view_df(d1)
```

```{r}
d2 <- d1 %>%
  mutate(parent_eng_comf = as.numeric(parent_eng_comf),
         youth_gender = factor(youth_gender),
         youth_age = as.numeric(youth_age))
# View(d2)
# view_df(d2)
```


```{r}
summary(d2)
```
# Inspect missingness patterns

outcomes with no NA:
y_sch_eng       
y_parsupp
y_parinv          
y_hw 
selfeffic_1 

predictors with no NA:
youth_gender
struct_1
convfut_1
knowschool_1
parnets_1
welcome_1
endorse_1      
supported_1      
ptrel_1

This figure shows:
80 rows have no missing values
5 rows are missing parent_eng_comf 
1 row is missing grades
3 rows are missing grades and parent_eng_comf
3 rows are missing gen_grades
1 row is missing acadhwi_1 and checkhwi_1
1 row is missing youth_age

```{r}
md.pattern(d2)
```

# Inspect missingness proportions

This plot shows proportion of missingness: 85% is not missing 
```{r}
nice_plot <- aggr(d2, col = c ('cornflowerblue', 'yellow'),
                  numbers = TRUE, sortVars = TRUE,
                  labels = names (d1), cex.axis = .7,
                  gap = 4, ylab = c ("Missing data", "Pattern"))
```
# Create a missingness or margin plot to further inspect missingness
```{r}
marginplot(d2[, c("acadhwi_1", "checkhwi_1")], col = mdc(1:2), cex = 1.2, cex.lab = 1.2, cex.numbers = 1.3, pch = 19) # only 2 variables at a time
```

### Imputation preprocessing

Following this instructions: https://library.virginia.edu/data/articles/getting-started-with-multiple-imputation-in-r

This person suggest to remove variables that have more than 25% misingness, character variables, and to remove variables that are highly correlated with others as that might mess up the imputations. Also they suggest not make any transformations at this point. 

# Specify a separate imputation model for variables of interest is they are not numerical (code from link above)

# Ordered categorical variables 
poly <- c("patriot_amident", "pid_x")

# Dichotomous variable
log <- c("manuf")

# Unordered categorical variable 
poly2 <- c("china_econ")

meth[poly] <- "polr"
meth[log] <- "logreg"
meth[poly2] <- "polyreg"

```{r}
d3 <- d2 %>%
  select(-school_id, -family_id, -participant_id)

# view_df(d3)

str(d3) # all except gender (factor) are numerical variables. 
```

### Imputation
```{r}
# We run the mice code with 0 iterations 
imp <- mice(d3, maxit=0)

# Extract predictorMatrix and methods of imputation 
predM <- imp$predictorMatrix
meth <- imp$method # Empty cells in the method matrix mean those variables will not be imputed

head(predM)
```
# Basic imputation using predictive mean matching (PMM), changing default number of imputed data sets from 5 to 20.
```{r}
imputed_data <- mice(d3, 
                     m = 50,
                     method = 'pmm',
                     print =  FALSE)

summary(imputed_data)

imputed_data$data$parent_eng_comf # this is still showing missing data
```

# Check out one of the complete data sets (the second of 20, in this case)
```{r}
imputed_data_set2 <- complete(imputed_data, action = 2)
# View(imputed_data_set2) # if we were doing single imputation, we'd stop here, but we are not.

nice_plot <- aggr(imputed_data_set2, col = c ('cornflowerblue', 'yellow'),
                  numbers = TRUE, sortVars = TRUE,
                  labels = names (d1), cex.axis = .7,
                  gap = 4, ylab = c ("Missing data", "Pattern")) # This plot show that there is no missing values now. 

imputed_data_set2$parent_eng_comf # checking completeness
```
## Now going back to the imputed_data

# Examine strip plot 
```{r}
stripplot(imputed_data, pch = 20, cex = 1.2) # Red dots are imputed values, blue are observed values
```

# Examine kernel density plot
```{r}
densityplot(imputed_data, scales = list(x = list(relation = "free")), layout = c(3, 1)) # Red lines are imputed value distributions, blue are observed value distributions
```

############################################################ standarizing variables - start ##################################################################

# Step 1: Convert to long format for processing
```{r}
imputed_long <- complete(imputed_data, action = "long", include = TRUE)

imputed_long <- imputed_long %>%
  mutate(youth_gender = as.numeric(youth_gender))

colnames(imputed_long)
```

# Step 2: Function to standardize within each imputed dataset
```{r}
standardize <- function(df) {
  df <- df %>%
    mutate(across(c(selfeffic_1, y_sch_eng, y_parsupp, y_parinv, y_hw, gen_grades, grades, parent_eng_comf, youth_age, acadhwi_1, checkhwi_1, struct_1, convfut_1, knowschool_1, parnets_1, welcome_1, endorse_1, supported_1, ptrel_1), ~ scale(.)[,1]))  # Standardizing variables
  return(df)
} # STANDARDIZING ALL EXCEPT GENDER THAT IS A FACTOR
```

# Step 3: Apply standardization within each imputed dataset
```{r}
imputed_long <- imputed_long %>%
  group_by(.imp) %>%
  group_modify(~ standardize(.x))

imputed_long <- imputed_long %>%
  mutate(youth_gender = factor(youth_gender),
         youth_gender = relevel(youth_gender, ref = "1")) # male
```

# Step 4: Convert back to `mids` object
```{r}
imputed_data_std <- as.mids(as.data.frame(imputed_long))
```


############################################################# standarizing variables  - end ###############################################################


### Analytic model fitting ###

# Multiple regression, outcome: y_sch_eng
```{r}
fit1 <- with(imputed_data, lm(y_sch_eng ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est1 <- pool(fit1)
summary(est1) # checkhwi_1  beta = 0.24, p < 0.01

pool.r.squared(fit1) # 0.23
```
# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas

# Multiple regression, outcome: y_sch_eng (standardized)
```{r}
fit1_st <- with(imputed_data_std, lm(y_sch_eng ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est1_st <- pool(fit1_st)
summary(est1_st) # checkhwi_1  beta = 0.31, p < 0.01

pool.r.squared(fit1_st) # 0.23
```

# Multiple regression, outcome: grades (youth report)
```{r}
fit2 <- with(imputed_data, lm(grades ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est2 <- pool(fit2)
summary(est2) 
# youth being female: beta = -0.56, p = 0.03
# convfut_1: beta = -0.42, p = 0.04

pool.r.squared(fit2) # 0.17
```

# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: grades (youth report) (standardized)
```{r}
fit2_st <- with(imputed_data_std, lm(grades ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est2_st <- pool(fit2_st)
summary(est2_st)
# youth being female: beta = -0.48, p = 0.03
# convfut_1: beta = -0.26, p = 0.04

pool.r.squared(fit2_st) # 0.17
```


# Multiple regression, outcome: hw best practices (youth report)
```{r}
fit3 <- with(imputed_data, lm(y_hw ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est3 <- pool(fit3)
summary(est3) # no predictors were significantly related with the outcome

pool.r.squared(fit3) # 0.15
```
# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: hw best practices (standardized)
```{r}
fit3_st <- with(imputed_data_std, lm(y_hw ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est3_st <- pool(fit3_st)
summary(est3_st) # no predictors were significantly related with the outcome

pool.r.squared(fit3_st) # 0.15
```

# Multiple regression, outcome: y_parsupp (youth report)
```{r}
fit4 <- with(imputed_data, lm(y_parsupp ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est4 <- pool(fit4)
summary(est4) # knowschool_1  beta = 0.41 p = 0.02

pool.r.squared(fit4) # 0.23
```
# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: y_parsupp (youth report) (standardized)
```{r}
fit4_st <- with(imputed_data_std, lm(y_parsupp ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est4_st <- pool(fit4_st)
summary(est4_st) # knowschool_1  beta = 0.35 p = 0.02

pool.r.squared(fit4_st) # 0.23
```


# Multiple regression, outcome: y_parinv (youth report)
```{r}
fit5 <- with(imputed_data, lm(y_parinv ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est5 <- pool(fit5)
summary(est5) 
# parent_eng_comf beta = -0.15, p = 0.01
# knowschool_1  beta = 0.41, p = 0.05

pool.r.squared(fit5) # 0.18
```

# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: y_parinv (youth report) (standardized)
```{r}
fit5_st <- with(imputed_data_std, lm(y_parinv ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est5_st <- pool(fit5_st)
summary(est5_st)
# parent_eng_comf beta = -0.29, p = 0.01
# knowschool_1  beta = 0.30, p = 0.05

pool.r.squared(fit5_st) # 0.18
```

# Multiple regression, outcome: self efficacy (parent report)
```{r}
fit6 <- with(imputed_data, lm(selfeffic_1 ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est6 <- pool(fit6)
summary(est6) 

# parent_eng_comf beta = 0.04, p = 0.03
# welcome_1 beta = 0.25, p = 0.02
# endorse_1  beta = 0.45, p < 0.001

pool.r.squared(fit6) # 0.68
```

# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: self efficacy (parent report) (standardized)
```{r}
fit6_st <- with(imputed_data_std, lm(selfeffic_1 ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est6_st <- pool(fit6_st)
summary(est6_st)
# parent_eng_comf beta = 0.16, p = 0.03
# welcome_1 beta = 0.26, p = 0.02
# endorse_1  beta = 0.46, p < 0.001

pool.r.squared(fit6_st) # 0.68
```
# Multiple regression, outcome: gen grades (parent report)
```{r}
fit7 <- with(imputed_data, lm(gen_grades ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est7 <- pool(fit7)
summary(est7) 

# youth being female: beta = -0.66, p = 0.003
# convfut_1 beta = -0.38, p = 0.03
# knowschool_1 beta = 0.72, p = 0.01
# parnets_1  beta = -0.45, p = 0.052 trending

pool.r.squared(fit7) # 0.29
```


# Step 5: Run regression on standardized data
# Step 6: Pool the results to get standardized betas
# Multiple regression, outcome: gen grades (parent report) (standardized)
```{r}
fit7_st <- with(imputed_data_std, lm(gen_grades ~ parent_eng_comf + youth_age + youth_gender + acadhwi_1 + checkhwi_1 + struct_1 + convfut_1 + knowschool_1 + parnets_1 + welcome_1 + endorse_1 + supported_1 + ptrel_1))

est7_st <- pool(fit7_st)
summary(est7_st)

# youth being female: beta = -0.66, p = 0.003
# convfut_1 beta = -0.25, p = 0.03
# knowschool_1 beta = 0.35, p = 0.01
# parnets_1  beta = -0.24, p = 0.052 trending

pool.r.squared(fit7_st) # 0.29
```
# trying to get the partial R sqrd for each predictor 
```{r}
# predictors <- c("predictor1", "predictor2", "predictor3")
# full_model_r2 <- pool.r.squared(full_model)$estimate[1]  # Full model R²
# 
# partial_r2_values <- sapply(predictors, function(pred) {
#   reduced_model <- with(imputed_data, lm(as.formula(paste("Y ~", paste(setdiff(predictors, pred), collapse = " + ")))))
#   reduced_r2 <- pool.r.squared(reduced_model)$estimate[1]
#   full_model_r2 - reduced_r2  # Contribution of the predictor
# })
# 
# partial_r2_values
```

